{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>LINEAR REGRESSION WITH TENSORFLOW</h2>\n",
    "\n",
    "<h3>Objective for this Notebook<h3>    \n",
    "<h5> 1. What is Linear Regression</h5>\n",
    "<h5> 2. Linear Regression with TensorFlow. </h5>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ref1\"></a>\n",
    "\n",
    "<h1>Linear Regression</h1>\n",
    "\n",
    "Defining a linear regression in simple terms, is the approximation of a linear model used to describe the relationship between two or more variables. In a simple linear regression there are two variables, the dependent variable, which can be seen as the \"state\" or \"final goal\" that we study and try to predict, and the independent variables, also known as explanatory variables, which can be seen as the \"causes\" of the \"states\".\n",
    "\n",
    "When more than one independent variable is present the process is called multiple linear regression. <br>\n",
    "When multiple dependent variables are predicted the process is known as multivariate linear regression.\n",
    "\n",
    "The equation of a simple linear model is\n",
    "\n",
    "$$Y = a X + b $$\n",
    "\n",
    "Where Y is the dependent variable and X is the independent variable, and <b>a</b> and <b>b</b> being the parameters we adjust. <b>a</b> is known as \"slope\" or \"gradient\" and <b>b</b> is the \"intercept\". You can interpret this equation as Y being a function of X, or Y being dependent on X.\n",
    "\n",
    "If you plot the model, you will see it is a line, and by adjusting the \"slope\" parameter you will change the angle between the line and the independent variable axis, and the \"intercept parameter\" will affect where it crosses the dependent variable's axis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pylab as pl\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define the independent variable:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.arange(0.0, 5.0, 0.1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##You can adjust the slope and intercept to verify the changes in the graph\n",
    "a = 1\n",
    "b = 0\n",
    "\n",
    "Y= a * X + b \n",
    "\n",
    "plt.plot(X, Y) \n",
    "plt.ylabel('Dependent Variable')\n",
    "plt.xlabel('Indepdendent Variable')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK... but how can we see this concept of linear relations with a more meaningful point of view?\n",
    "\n",
    "Simple linear relations were used to try to describe and quantify many observable physical phenomena, the easiest to understand are speed and distance traveled:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Distance Traveled = Speed \\times Time + Initial Distance$$\n",
    "\n",
    "$$Speed = Acceleration \\times Time + Initial Speed$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They are also used to describe properties of different materials:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Force = Deformation \\times Stiffness$$\n",
    "\n",
    "$$Heat Transfered = Temperature Difference \\times Thermal Conductivity$$\n",
    "\n",
    "$$Electrical Tension (Voltage) = Electrical Current \\times Resistance$$\n",
    "\n",
    "$$Mass =  Volume \\times Density$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we perform an experiment and gather the data, or if we already have a dataset and we want to perform a linear regression, what we will do is adjust a simple linear model to the dataset, we adjust the \"slope\" and \"intercept\" parameters to the data the best way possible, because the closer the model comes to describing each ocurrence, the better it will be at representing them.\n",
    "\n",
    "So how is this \"regression\" performed?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ref2\"></a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Understanding the Data</h2>\n",
    "\n",
    "<h3><code>FuelConsumption.csv</code>:</h3>\n",
    "We have downloaded a fuel consumption dataset, <b><code>FuelConsumption.csv</code></b>, which contains model-specific fuel consumption ratings and estimated carbon dioxide emissions for new light-duty vehicles for retail sale in Canada. <a href=\"http://open.canada.ca/data/en/dataset/98f1a129-f628-4ce4-b24d-6f16bf24dd64?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDL0120ENSkillsNetwork20629446-2021-01-01\">Dataset source</a>\n",
    "\n",
    "*   **MODELYEAR** e.g. 2014\n",
    "*   **MAKE** e.g. Acura\n",
    "*   **MODEL** e.g. ILX\n",
    "*   **VEHICLE CLASS** e.g. SUV\n",
    "*   **ENGINE SIZE** e.g. 4.7\n",
    "*   **CYLINDERS** e.g 6\n",
    "*   **TRANSMISSION** e.g. A6\n",
    "*   **FUEL CONSUMPTION in CITY(L/100 km)** e.g. 9.9\n",
    "*   **FUEL CONSUMPTION in HWY (L/100 km)** e.g. 8.9\n",
    "*   **FUEL CONSUMPTION COMB (L/100 km)** e.g. 9.2\n",
    "*   **CO2 EMISSIONS (g/km)** e.g. 182   --> low --> 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"FuelConsumption.csv\")\n",
    "\n",
    "# take a look at the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets say we want to use linear regression to predict Co2Emission of cars based on their engine size. So, lets define X and Y value for the linear regression, that is, train_x and train_y:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.asanyarray(df[['ENGINESIZE']])\n",
    "train_y = np.asanyarray(df[['CO2EMISSIONS']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we initialize the variables <b>a</b> and <b>b</b>, with any random guess, and then we define the linear function:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.Variable(20.0)\n",
    "b = tf.Variable(30.2)\n",
    "\n",
    "\n",
    "def h(x):\n",
    "   y = a*x + b\n",
    "   return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are going to define a loss function for our regression, so we can train our model to better fit our data. In a linear regression, we minimize the squared error of the difference between the predicted values(obtained from the equation) and the target values (the data that we have). In other words we want to minimize the square of the predicted values minus the target value. So we define the equation to be minimized as loss.\n",
    "\n",
    "To find value of our loss, we use <b>tf.reduce_mean()</b>. This function finds the mean of a multidimensional tensor, and the result can have a different dimension.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_object(y,train_y) :\n",
    "    return tf.reduce_mean(tf.square(y - train_y))\n",
    "    # Below is a predefined method offered by TensorFlow to calculate loss function\n",
    "    #loss_object = tf.keras.losses.MeanSquaredLogarithmicError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to start training and run the graph. We use GradientTape to calculate gradients:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "train_data = []\n",
    "loss_values =[]\n",
    "a_values = []\n",
    "b_values = []\n",
    "# steps of looping through all your data to update the parameters\n",
    "training_epochs = 200\n",
    "\n",
    "# train model\n",
    "for epoch in range(training_epochs):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_predicted = h(train_x)\n",
    "        loss_value = loss_object(train_y,y_predicted)\n",
    "        loss_values.append(loss_value)\n",
    "\n",
    "        # get gradients\n",
    "        gradients = tape.gradient(loss_value, [b,a])\n",
    "        \n",
    "        # compute and adjust weights\n",
    "        a_values.append(a.numpy())\n",
    "        b_values.append(b.numpy())\n",
    "        b.assign_sub(gradients[0]*learning_rate)\n",
    "        a.assign_sub(gradients[1]*learning_rate)\n",
    "        if epoch % 5 == 0:\n",
    "            train_data.append([a.numpy(), b.numpy()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets plot the loss values to see how it has changed during the training:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.plot(loss_values, 'ro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets visualize how the coefficient and intercept of line has changed to fit the data:\n",
    "\n",
    "The green dots are the data points, the red lines are created using the a and b coefficients during training, and the black line is the line we use to model the relationship with the final/last coefficients.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(train_x, train_y, color='green')\n",
    "for a,b in zip(a_values[0:len(a_values)], b_values[0:len(b_values)]):\n",
    "    plt.plot(train_x,a*train_x+b, color='red', linestyle='dashed')\n",
    "plt.plot(train_x,a_values[-1]*train_x+b_values[-1], color='black')\n",
    "\n",
    "final = mpatches.Patch(color='Black', label='Final')\n",
    "estimates = mpatches.Patch(color='Red', label='Estimates')\n",
    "data = mpatches.Patch(color='Green', label='Data Points')\n",
    "\n",
    "plt.legend(handles=[data, estimates, final])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
